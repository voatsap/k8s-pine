apiVersion: v1
kind: Pod
metadata:
  name: gpu-workload
  labels:
    app: gpu-workload
    workload-type: gpu
spec:
  tolerations:
  - key: "gpu"
    operator: "Equal"
    value: "nvidia"
    effect: "NoSchedule"
  nodeSelector:
    workload-type: gpu
  containers:
  - name: gpu-app
    image: nvidia/cuda:11.0-runtime-ubuntu20.04
    command: ["sleep", "3600"]
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
  restartPolicy: Never
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-deployment
  labels:
    app: gpu-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gpu-deployment
  template:
    metadata:
      labels:
        app: gpu-deployment
        workload-type: gpu
    spec:
      tolerations:
      - key: "gpu"
        operator: "Equal"
        value: "nvidia"
        effect: "NoSchedule"
      nodeSelector:
        workload-type: gpu
      containers:
      - name: gpu-app
        image: tensorflow/tensorflow:latest-gpu
        command: ["python", "-c", "import time; time.sleep(3600)"]
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
